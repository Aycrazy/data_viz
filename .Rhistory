tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
predictCART = predict(tweetCART, newdata=testSparse, type="class")
table(testSparse$Negative, predictCART)
tweets <- read.csv("~/Downloads/tweets.csv", comment.char="#")
View(tweets)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
stopwords("english")[1:10]
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
inspect(frequencies[1000:1005,505:515])
sparse = removeSparseTerms(frequencies, 0.995)
tweetsSparse = as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) = make.names(colnames(tweetsSparse))
tweets$Negative = as.factor(tweets$Avg <= -1)
View(tweets)
View(tweets)
tweetsSparse$Negative = tweets$Negative
set.seed(123)
split = sample.split(tweetsSparse$Negative, SplitRatio = 0.7)
trainSparse = subset(tweetsSparse, split==TRUE)
testSparse = subset(tweetsSparse, split==FALSE)
tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
predictCART = predict(tweetCART, newdata=testSparse, type="class")
table(testSparse$Negative, predictCART)
tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
prp(tweetCART)
# Evaluate the performance of the model
predictCART = predict(tweetCART, newdata=testSparse, type="class")
table(testSparse$Negative, predictCART)
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
tweets <- read.csv("~/Downloads/tweets.csv", comment.char="#")
View(tweets)
tweets$Negative = as.factor(tweets$Avg <= -1)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
inspect(frequencies[1000:1005,505:515])
sparse = removeSparseTerms(frequencies, 0.995)
tweetsSparse = as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) = make.names(colnames(tweetsSparse))
tweetsSparse$Negative = tweets$Negative
set.seed(123)
split = sample.split(tweetsSparse$Negative, SplitRatio = 0.7)
trainSparse = subset(tweetsSparse, split==TRUE)
testSparse = subset(tweetsSparse, split==FALSE)
tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
predictCART = predict(tweetCART, newdata=testSparse, type="class")
table(testSparse$Negative, predictCART)
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("caTools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("grid", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("gtools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("gtable", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("Matrix", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("pbkrtest", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("rpart", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("rpart.plot", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("SnowballC", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("tools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
tweets <- read.csv("~/Downloads/tweets.csv", comment.char="#")
View(tweets)
table(testSparse$Negative, predictCART)
table(testSparse$Negative, predictCART)
tweets$Negative = as.factor(tweets$Avg <= -1)
corpus = Corpus(VectorSource(tweets$Tweet))
library("randomForest", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
inspect(frequencies[1000:1005,505:515])
sparse = removeSparseTerms(frequencies, 0.995)
tweetsSparse = as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) = make.names(colnames(tweetsSparse))
tweetsSparse$Negative = tweets$Negative
set.seed(123)
split = sample.split(tweetsSparse$Negative, SplitRatio = 0.7)
trainSparse = subset(tweetsSparse, split==TRUE)
testSparse = subset(tweetsSparse, split==FALSE)
tweetCART = rpart(Negative ~ ., data=trainSparse, method="class")
predictCART = predict(tweetCART, newdata=testSparse, type="class")
table(testSparse$Negative, predictCART)
tweetlog = glm(Negative~., data = trainSparse, method="class")
predictions = predict(tweetLog, newdata=testSparse, type="response")
predictions = predict(tweetlog, newdata=testSparse, type="response")
tweetlog = glm(Negative~., data = trainSparse)
predictions = predict(tweetlog, newdata=testSparse, type="response")
glm(Negative ~., family =binomial. data=trainSparse)
install.packages("sp")
library("sp", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
glm(Negative ~., family =binomial. data=trainSparse)
glm(Negative ~., family =binomial, data=trainSparse)
predictions = predict(tweetlog, newdata=testSparse, type="response")
tweet = glm(Negative~., family=binomail, data=trainSparse)
tweet = glm(Negative~., family=binomial, data=trainSparse)
tweetlog = glm(Negative~., family=binomial, data=trainSparse)
predictions = predict(tweetlog, newdata=testSparse, type="response")
table(testSparse$Negative, predictions >= .5)
173/(91+173)
enron <- read.csv("~/Downloads/energy_bids.csv")
View(enron)
corpus = Corpus(VectorSource(enron$email))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
library(tm)
library(tm)
dtm = DocumentTermMatrix(corpus)
rstudioDiagnosticsReport()
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("caTools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("rpart", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("rpart.plot", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("SnowballC", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("tools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("stringr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
wiki <- read.csv("~/Downloads/wiki.csv")
View(wiki)
summary(wiki)
str(wiki)
table(wiki$Vandal)
corpusAdded = Corpus(VectorSource(wiki$Added))
stopwords("english")[1:10]
corpusAdded = tm_map(corpus, removeWords, stopwords("english"))
corpusAdded = tm_map(corpusAdded, stemDocument)
dtmAdded = DocumentTermMatrix(corpusAdded)
dtmAdded
corpusAdded = Corpus(VectorSource(wiki$Added))
corpusAdded = tm_map(corpusAdded, removeWords, stopwords("english"))
corpusAdded = tm_map(corpusAdded, stemDocument)
dtmAdded = DocumentTermMatrix(corpusAdded)
dtmAdded
sparse = removeSparseTerms(dtmAdded, 0.997)
sparse = removeSparseTerms(dtmAdded, 0.997)
wikiSparse = as.data.frame(as.matrix(sparse))
wikiSparse
str(wikiSparse)
summary(wikiSparse)
table(wikiSparse)
wikiSparse = as.data.frame(as.matrix(sparse))
wordsAdded = wikiSparse
colnames(wordsAdded) = paste("A", colnames(wordsAdded))
View(wiki)
View(wikiSparse)
View(wordsAdded)
corpusRemoved = Corpus(VectorSource(wiki$Removed))
corupsRemoved = tm_map(corpusRemoved, removeWords, stopwords("english"))
corpusRemoved = tm_map(corpusRemoved, stemDocument)
dtmRemoved = DocumentTermMatrix(corpusRemoved)
wordsSparse = removeSparseTerms(frequencies, 0.997)
wordsRemoved = as.data.frame(as.matrix(wordsSparse))
colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))
wordsRemoved
str(wordsRemoved)
ncol(wordsRemoved)
wordsSparse = removeSparseTerms(dtmRemoved, 0.997)
wordsRemoved = as.data.frame(as.matrix(wordsSparse))
colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))
ncol(wordsRemoved)
grepl("cat","dogs and cats",fixed=TRUE) # TRUE
grepl("cat","dogs and rats",fixed=TRUE) # FALSE
wikiWords = wordsRemoved
wikiWords$HTTP = ifelse(grepl("http",wiki$Added,fixed=TRUE), 1, 0)
View(wikiWords)
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("SparseM", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("SnowballC", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("caTools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
IAProQAReport <- read.delim("~/Desktop/Internships: Jobs/IAProQAReport.txt", header=FALSE, row.names=NULL)
View(IAProQAReport)
IAProReport = IAProQAReport(-c(1:4),)
IAProReport = IAProQAReport[-c(1:4),]
IAProReport = IAProReport[c(),(3)]
IAProQAReport <- read.delim("~/Desktop/Internships: Jobs/IAProQAReport.txt", header=FALSE, row.names=NULL)
View(IAProQAReport)
IAProReport = IAProQAReport[-c(1:4),]
IAProReport = IAProQAReport[-c(,(4))
)
IAProReport = IAProQAReport[-c(,(4))]
IAProReport = IAProQAReport[-c(1:3616),(4))]
IAProReport = IAProQAReport[-c(1:3616),(4)]
IAProReport = IAProQAReport[-c(1:4),]
IAProReport = IAProQAReport[c(1:3616),(1,2)]
IAProReport = IAProQAReport[c(1:3616),(1:2)]
View(IAProReport)
table(IAProReport$V2)
IAProReportTally = as.data.frame(table(IAProReport))
View(IAProReportTally)
IAProReportTally = subset(IAProReportTally, IAProQAReport$Freq > 1)
IAProReportTally = as.data.frame(table(IAProReport))
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = subset(IAProReportTally, IAProQAReport$Var1 !=" ")
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = subset(IAProReportTally, IAProQAReport$Var1 > 0)
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = subset(IAProReportTally, IAProQAReport$Freq != 841)
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = IAProReportTally[c(1,)]
IAProReportTally = IAProReportTally[-c((1),)]
IAProReportTally = IAProReportTally[-c(1),]
IAProReportTally = subset(IAProReportTally, IAProQAReport$Var1 != "< The quality assurance check has been run for this incident and no issues were found >")
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = IAProReportTally[-c(1),]
IAProReportTally = IAProReportTally[-c(34),]
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = IAProReportTally[-c(1),]
IAProReportTally = IAProReportTally[-c(33),]
corpus = Corpus(VectorSource(IAProReportTally$Var1))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removePunctuation)
View(corups)
View(corpus)
View(as.data.frame(corpus)
)
stopwords("english")[1:10]
corpus = tm_map(corpus, removewords, c(stopwords("english")))
corpus = tm_map(corpus, removeWords, c(stopwords("english")))
corpus = tm_map(corpus, removeWords, c(stopwords("english")))
corpus = tm_map(corpus, stemDocument)
corpus = Corpus(VectorSource(IAProReportTally$Var1))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeWords, c(stopwords("english")))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.999)
IAProSparse = as.data.frame(as.matrix(sparse))
colnames(IAProSparse) = make.names(colnames(IAproSparse))
colnames(IAProSparse) = make.names(colnames(IAProSparse))
View(IAProSparse)
table(IAProReportTally$Var1)
View(IAProReportTally)
View(IAProReportTally)
View(IAProReportTally)
write.table(IAReportTally, "c:/IAReportTally.csv", sep="\t")
write.table(IAProReportTally, "c:/IAProReportTally.csv", sep="\t")
write.table(IAProReportTally, "c:/Desktop", sep="\t")
write.table(IAProReportTally, "~/Desktop/Internships: Jobs/", sep="\t")
write.table(IAProReportTally, "~/Desktop/Internships: Jobs/IAProTally.csv", sep="\t")
write.table(IAProReportTally, "~/Desktop/Internships: Jobs/IAProTally.csv", sep=",")
install.packages("medics")
install.packages("memisc")
library("memisc", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
(IAProReportTally <- within(IAProReportTally,{
Var1 =cases(
"no linked allegation"="no linked allegation"
)
}))
(IAProReportTally <- within(IAProReportTally,{
Var1 =cases(
"no linked allegation"="no linked allegation",
)
}))
(IAProReportTally <- within(IAProReportTally,{
Var1 =cases(
"no linked allegation"="no linked allegation",
)
}))
(IAProReportTally <- within(IAProReportTally,{
Var1 =cases(
"allegation"="no linked allegation",
"phone"="no linked phone number"
)
}))
grepl("alleged",IAProReportTally$Var1)
grepl("allegation",IAProReportTally$Var1)
(IAProReportTally <- within(IAProReportTally,{
+    Var1 =cases(
+         grepl("allegation",IAProReportTally$Var1)==TRUE="no linked allegation",
+         grepl("phone",IAProReportTally$Var1)==TRUE="no linked phone number"
+    )
+ }))
(IAProReportTally <- within(IAProReportTally,{
+    Var1 =cases(
+         grepl("allegation",IAProReportTally$Var1)=TRUE="no linked allegation",
+         grepl("phone",IAProReportTally$Var1)=TRUE="no linked phone number"
+    )
+ }))
IAProNoAllegation = subset(IAProReportTally,grepl("allegation",IAProReportTally$Var1)=TRUE)
IAProNoAllegation = subset(IAProReportTally,grepl("allegation",IAProReportTally$Var1)==TRUE)
View(IAProNoAllegation)
IAProNoPhone = subset(IAProReportTally,grepl("phone",IAProReportTally$Var1)==TRUE)
IAProNoAddress = subset(IAProReportTally,grepl("address",IAProReportTally$Var1)==TRUE)
IAProNoOfficer = subset(IAProReportTally,grepl("officer",IAProReportTally$Var1)==TRUE)
IAProNoCitizen = subset(IAProReportTally,grepl("citizen",IAProReportTally$Var1)==TRUE)
IAProNoUseOfForce = subset(IAProReportTally,grepl("use of force",IAProReportTally$Var1)==TRUE)
View(IAProNoUseOfForce)
IAProNoUseOfForce = subset(IAProReportTally,grepl("use of force"|"uses of force",IAProReportTally$Var1)==TRUE)
IAProNoUseOfForce = subset(IAProReportTally,grepl("uses of force",IAProReportTally$Var1)==TRUE)
IAProNoResolution = subset(IAProReportTally,grepl("resolve",IAProReportTally$Var1)==TRUE)
IAProSimple = data.frame(nrow("IAProNoAllegation","IAProNoPhone","IAProNoAddress","IAProNoOfficer","IAProNoCitizen","IAProNoUseOfForce"))
IAProSimple = data.frame()
IAProSimple = nrow("IAProNoAllegation","IAProNoPhone","IAProNoAddress","IAProNoOfficer","IAProNoCitizen","IAProNoUseOfForce")
IAProSimple = merge("IAProNoAllegation","IAProNoPhone","IAProNoAddress","IAProNoOfficer","IAProNoCitizen","IAProNoUseOfForce")
IAProSimple = merge("IAProNoAllegation$Var1","IAProNoPhone$Var1","IAProNoAddress$Var1","IAProNoOfficer$Var1","IAProNoCitizen$Var1","IAProNoUseOfForce$Var1")
IAProSimple = merge(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce,by.x="Var1", by.y="Freq")
IAProSimple = merge(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce,by.x="Var1")
IAProSimple = merge(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce,by.x="Var1", by.y="Freq")
IAProSimple = merge(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce,by.x="Var1", by=c("Var1","Freq"))
IAProSimple = rbind(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce)
View(IAProSimple)
View(IAProNoAddress)
sum(IAProNoAddress$Freq)
sum(IAProNolAllegation$Freq)
sum(IAProNoAllegation$Freq)
sum(IAProNoCitizen)
sum(IAProNoCitizen$Freq)
sum(IAProNoOfficer$Freq)
sum(IAProNoPhone$Freq)
sum(IAProNoResolution$Freq)
sum(IAProNoUseOfForce$Freq)
View(IAProNoAddress)
View(IAProNoAddress)
View(IAProNoAllegation)
View(IAProNoAllegation)
View(IAProNoCitizen)
View(IAProNoOfficer)
View(IAProNoPhone)
View(IAProNoResolution)
View(IAProNoUseOfForce)
View(IAProReport)
View(IAProReportTally)
View(IAProSimple)
View(IAProSparse)
View(IAProSimple)
View(IAProNoAddress)
View(IAProNoAddress)
View(IAProNoAddress)
View(IAProNoAddress)
getwd()
rm(ls)
rm(list=ls, All=TRUE)
rm(list=ls)
rm(list=ls())
my_variable <- 10
my_variable
my_variable <- 10
my_variable
rm(list=ls())
my_variable <- 10
library(tidyverse)
library(tidyr)
ggpot(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
ggplot(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
library(ggplot2)
ggplot2(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
ggplot(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
load(mtcars)
read_table(mtcars)
library(dplyr)
read_table(mtcars)
library(datasets)
load(mtcars)
data(mtcars)
head(mtcars)
ggplot(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
ggplot(data=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
ggplot(data=mpg)+
geom_point(mapping = aes(x = displ, y = hwy))
filter(mpg, cyl = 8)
filter(mpg, cyl == 8)
filter(diamond, carat > 3)
library(help="datasets")
data(diamonds)
filter(diamond, carat > 3)
filter(diamonds, carat > 3)
rm(list=ls())
library(nycflights13)
library(tidyverse)
install.packages('tidyverse')
install.packages('nycflights13')
library(nycflights13)
library(tidyverse)
ndsuh <- load('~/Downloads/NSDUH-2015-DS0001-bndl-data-r/NSDUH-2015-DS0001-data/NSDUH-2015-DS0001-data-r.rda')
View(PUF2015_102016)
rm(list=ls())
library(nycflights13)
data(nycflights13)
data("flights")
View(flights)
flights %<% filter(dep_delay >= 2)
flights %.% filter(dep_delay >= 2)
flights %>% filter(dep_delay >= 2)
flights %>% filter(dest == 'IAH' | dest == 'HOU')
flights %>% filter(dest == 'DL' | carrier == 'UA')
library(dplyr)
flights %>% filter(between(air_time,0,260))
setwd('~/Documents/data_viz/')
library(tidyverse)
library(readr)
library(stringr)
library(dplyr)
library(readxl)
library(ggmap)
library(acs)
library(RSocrata)
library(data.table)
ssl <- data.frame(read_csv('Strategic_Subject_List.csv'))
ssl_wt <- ssl %>% filter(!is.na(CENSUS.TRACT)) %>%
filter(CENSUS.TRACT != "0")
ssl_wt_drug <- ssl_wt %>% filter(DRUG.I == 'Y')
View(ssl)
to_replace = colnames(ssl_wt_drug)
replace_with = gsub("[.]","_",tolower(colnames(ssl_wt_drug)))
ssl_wt_drug <- setnames(ssl_wt_drug, c(to_replace), c(replace_with))
plot1 <- ggplot(data = ssl_wt_drug, aes(x = age_curr, y = predictor_rat_narcotic_arrests, color = race_code_cd))+
geom_boxplot()
plot1 + labs(title = "How Age and Race Impact Predict Narcotics Arrest Score", subtitle = "We will take a look at how age and race impact predicted narcotics arrest score",
caption = "Source: City of Chicago Data") + ylab('Predicted Number of Narcotics Arrests') + xlab('Age Range of Last Arrest')
plot1 + labs(title = "How Age and Race Impact Predict Narcotics Arrest Score", subtitle = "We will take a look at how age and race impact predicted narcotics arrest score",
caption = "Source: City of Chicago Data") + ylab('Predicted Number of Narcotics Arrests') + xlab('Age Range of Last Arrest')
setwd('~/Documents/data_viz/')
library(tidyverse)
library(readr)
library(stringr)
library(dplyr)
library(readxl)
library(ggmap)
library(acs)
library(RSocrata)
library(data.table)
ssl <- data.frame(read_csv('Strategic_Subject_List.csv'))
ssl_wt <- ssl %>% filter(!is.na(CENSUS.TRACT)) %>%
filter(CENSUS.TRACT != "0")
ssl_wt_drug <- ssl_wt %>% filter(DRUG.I == 'Y')
to_replace = colnames(ssl_wt_drug)
replace_with = gsub("[.]","_",tolower(colnames(ssl_wt_drug)))
ssl_wt_drug <- setnames(ssl_wt_drug, c(to_replace), c(replace_with))
plot1 <- ggplot(data = ssl_wt_drug, aes(x = age_curr, y = predictor_rat_narcotic_arrests, color = race_code_cd))+
geom_boxplot()
plot1 + labs(title = "How Age and Race Impact Predict Narcotics Arrest Score", subtitle = "We will take a look at how age and race impact predicted narcotics arrest score",
caption = "Source: City of Chicago Data") + ylab('Predicted Number of Narcotics Arrests') + xlab('Age Range of Last Arrest')
install.packages(tidyverse)
install.packages(readr)
install.packages(stringr)
install.packages(dplyr)
install.packages(readxl)
install.packages(ggmap)
install.packages(acs)
install.packages(RSocrata)
install.packages(data.table)
install.packages('tidyverse')
install.packages('readr')
install.packages('stringr')
install.packages('dplyr')
install.packages('readxl')
install.packages('tidyverse')
install.packages('readr')
install.packages('stringr')
install.packages('dplyr')
install.packages('readxl')
install.packages('ggmap')
install.packages(acs)
install.packages(RSocrata)
install.packages(data.table)
install.packages('acs')
install.packages('RSocrata')
install.packages('data.table')
install.packages('ggplot2')
install.packages("ggplot2")
install.packages("tidyverse")
setwd('~/Documents/data_viz/')
library(tidyverse)
library(readr)
library(stringr)
library(dplyr)
library(readxl)
library(ggmap)
library(acs)
library(RSocrata)
library(data.table)
plot1 + labs(title = "How Age and Race Impact Predict Narcotics Arrest Score", subtitle = "We will take a look at how age and race impact predicted narcotics arrest score",
caption = "Source: City of Chicago Data") + ylab('Predicted Number of Narcotics Arrests') + xlab('Age Range of Last Arrest')
?ggplot2
plot1 + ggtitle(title = "How Age and Race Impact Predict Narcotics Arrest Score", subtitle = "We will take a look at how age and race impact predicted narcotics arrest score",
caption = "Source: City of Chicago Data") + ylab('Predicted Number of Narcotics Arrests') + xlab('Age Range of Last Arrest')
?labs
plot1 + labs(title = "How Age and Race Impact Predict Narcotics Arrest Score", subtitle = "We will take a look at how age and race impact predicted narcotics arrest score",
caption = "Source: City of Chicago Data") + ylab('Predicted Number of Narcotics Arrests') + xlab('Age Range of Last Arrest')
