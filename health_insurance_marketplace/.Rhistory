table(testSparse$Negative, predictions >= .5)
173/(91+173)
enron <- read.csv("~/Downloads/energy_bids.csv")
View(enron)
corpus = Corpus(VectorSource(enron$email))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
library(tm)
library(tm)
dtm = DocumentTermMatrix(corpus)
rstudioDiagnosticsReport()
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("caTools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("rpart", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("rpart.plot", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("SnowballC", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("tools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("stringr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
wiki <- read.csv("~/Downloads/wiki.csv")
View(wiki)
summary(wiki)
str(wiki)
table(wiki$Vandal)
corpusAdded = Corpus(VectorSource(wiki$Added))
stopwords("english")[1:10]
corpusAdded = tm_map(corpus, removeWords, stopwords("english"))
corpusAdded = tm_map(corpusAdded, stemDocument)
dtmAdded = DocumentTermMatrix(corpusAdded)
dtmAdded
corpusAdded = Corpus(VectorSource(wiki$Added))
corpusAdded = tm_map(corpusAdded, removeWords, stopwords("english"))
corpusAdded = tm_map(corpusAdded, stemDocument)
dtmAdded = DocumentTermMatrix(corpusAdded)
dtmAdded
sparse = removeSparseTerms(dtmAdded, 0.997)
sparse = removeSparseTerms(dtmAdded, 0.997)
wikiSparse = as.data.frame(as.matrix(sparse))
wikiSparse
str(wikiSparse)
summary(wikiSparse)
table(wikiSparse)
wikiSparse = as.data.frame(as.matrix(sparse))
wordsAdded = wikiSparse
colnames(wordsAdded) = paste("A", colnames(wordsAdded))
View(wiki)
View(wikiSparse)
View(wordsAdded)
corpusRemoved = Corpus(VectorSource(wiki$Removed))
corupsRemoved = tm_map(corpusRemoved, removeWords, stopwords("english"))
corpusRemoved = tm_map(corpusRemoved, stemDocument)
dtmRemoved = DocumentTermMatrix(corpusRemoved)
wordsSparse = removeSparseTerms(frequencies, 0.997)
wordsRemoved = as.data.frame(as.matrix(wordsSparse))
colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))
wordsRemoved
str(wordsRemoved)
ncol(wordsRemoved)
wordsSparse = removeSparseTerms(dtmRemoved, 0.997)
wordsRemoved = as.data.frame(as.matrix(wordsSparse))
colnames(wordsRemoved) = paste("R", colnames(wordsRemoved))
ncol(wordsRemoved)
grepl("cat","dogs and cats",fixed=TRUE) # TRUE
grepl("cat","dogs and rats",fixed=TRUE) # FALSE
wikiWords = wordsRemoved
wikiWords$HTTP = ifelse(grepl("http",wiki$Added,fixed=TRUE), 1, 0)
View(wikiWords)
library("tm", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("SparseM", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("SnowballC", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("caTools", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
IAProQAReport <- read.delim("~/Desktop/Internships: Jobs/IAProQAReport.txt", header=FALSE, row.names=NULL)
View(IAProQAReport)
IAProReport = IAProQAReport(-c(1:4),)
IAProReport = IAProQAReport[-c(1:4),]
IAProReport = IAProReport[c(),(3)]
IAProQAReport <- read.delim("~/Desktop/Internships: Jobs/IAProQAReport.txt", header=FALSE, row.names=NULL)
View(IAProQAReport)
IAProReport = IAProQAReport[-c(1:4),]
IAProReport = IAProQAReport[-c(,(4))
)
IAProReport = IAProQAReport[-c(,(4))]
IAProReport = IAProQAReport[-c(1:3616),(4))]
IAProReport = IAProQAReport[-c(1:3616),(4)]
IAProReport = IAProQAReport[-c(1:4),]
IAProReport = IAProQAReport[c(1:3616),(1,2)]
IAProReport = IAProQAReport[c(1:3616),(1:2)]
View(IAProReport)
table(IAProReport$V2)
IAProReportTally = as.data.frame(table(IAProReport))
View(IAProReportTally)
IAProReportTally = subset(IAProReportTally, IAProQAReport$Freq > 1)
IAProReportTally = as.data.frame(table(IAProReport))
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = subset(IAProReportTally, IAProQAReport$Var1 !=" ")
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = subset(IAProReportTally, IAProQAReport$Var1 > 0)
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = subset(IAProReportTally, IAProQAReport$Freq != 841)
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = IAProReportTally[c(1,)]
IAProReportTally = IAProReportTally[-c((1),)]
IAProReportTally = IAProReportTally[-c(1),]
IAProReportTally = subset(IAProReportTally, IAProQAReport$Var1 != "< The quality assurance check has been run for this incident and no issues were found >")
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = IAProReportTally[-c(1),]
IAProReportTally = IAProReportTally[-c(34),]
IAProReportTally = as.data.frame(table(IAProReport$V2))
IAProReportTally = IAProReportTally[-c(1),]
IAProReportTally = IAProReportTally[-c(33),]
corpus = Corpus(VectorSource(IAProReportTally$Var1))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removePunctuation)
View(corups)
View(corpus)
View(as.data.frame(corpus)
)
stopwords("english")[1:10]
corpus = tm_map(corpus, removewords, c(stopwords("english")))
corpus = tm_map(corpus, removeWords, c(stopwords("english")))
corpus = tm_map(corpus, removeWords, c(stopwords("english")))
corpus = tm_map(corpus, stemDocument)
corpus = Corpus(VectorSource(IAProReportTally$Var1))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeWords, c(stopwords("english")))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
inspect(frequencies[1000:1005,505:515])
findFreqTerms(frequencies, lowfreq=20)
sparse = removeSparseTerms(frequencies, 0.999)
IAProSparse = as.data.frame(as.matrix(sparse))
colnames(IAProSparse) = make.names(colnames(IAproSparse))
colnames(IAProSparse) = make.names(colnames(IAProSparse))
View(IAProSparse)
table(IAProReportTally$Var1)
View(IAProReportTally)
View(IAProReportTally)
View(IAProReportTally)
write.table(IAReportTally, "c:/IAReportTally.csv", sep="\t")
write.table(IAProReportTally, "c:/IAProReportTally.csv", sep="\t")
write.table(IAProReportTally, "c:/Desktop", sep="\t")
write.table(IAProReportTally, "~/Desktop/Internships: Jobs/", sep="\t")
write.table(IAProReportTally, "~/Desktop/Internships: Jobs/IAProTally.csv", sep="\t")
write.table(IAProReportTally, "~/Desktop/Internships: Jobs/IAProTally.csv", sep=",")
install.packages("medics")
install.packages("memisc")
library("memisc", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
(IAProReportTally <- within(IAProReportTally,{
Var1 =cases(
"no linked allegation"="no linked allegation"
)
}))
(IAProReportTally <- within(IAProReportTally,{
Var1 =cases(
"no linked allegation"="no linked allegation",
)
}))
(IAProReportTally <- within(IAProReportTally,{
Var1 =cases(
"no linked allegation"="no linked allegation",
)
}))
(IAProReportTally <- within(IAProReportTally,{
Var1 =cases(
"allegation"="no linked allegation",
"phone"="no linked phone number"
)
}))
grepl("alleged",IAProReportTally$Var1)
grepl("allegation",IAProReportTally$Var1)
(IAProReportTally <- within(IAProReportTally,{
+    Var1 =cases(
+         grepl("allegation",IAProReportTally$Var1)==TRUE="no linked allegation",
+         grepl("phone",IAProReportTally$Var1)==TRUE="no linked phone number"
+    )
+ }))
(IAProReportTally <- within(IAProReportTally,{
+    Var1 =cases(
+         grepl("allegation",IAProReportTally$Var1)=TRUE="no linked allegation",
+         grepl("phone",IAProReportTally$Var1)=TRUE="no linked phone number"
+    )
+ }))
IAProNoAllegation = subset(IAProReportTally,grepl("allegation",IAProReportTally$Var1)=TRUE)
IAProNoAllegation = subset(IAProReportTally,grepl("allegation",IAProReportTally$Var1)==TRUE)
View(IAProNoAllegation)
IAProNoPhone = subset(IAProReportTally,grepl("phone",IAProReportTally$Var1)==TRUE)
IAProNoAddress = subset(IAProReportTally,grepl("address",IAProReportTally$Var1)==TRUE)
IAProNoOfficer = subset(IAProReportTally,grepl("officer",IAProReportTally$Var1)==TRUE)
IAProNoCitizen = subset(IAProReportTally,grepl("citizen",IAProReportTally$Var1)==TRUE)
IAProNoUseOfForce = subset(IAProReportTally,grepl("use of force",IAProReportTally$Var1)==TRUE)
View(IAProNoUseOfForce)
IAProNoUseOfForce = subset(IAProReportTally,grepl("use of force"|"uses of force",IAProReportTally$Var1)==TRUE)
IAProNoUseOfForce = subset(IAProReportTally,grepl("uses of force",IAProReportTally$Var1)==TRUE)
IAProNoResolution = subset(IAProReportTally,grepl("resolve",IAProReportTally$Var1)==TRUE)
IAProSimple = data.frame(nrow("IAProNoAllegation","IAProNoPhone","IAProNoAddress","IAProNoOfficer","IAProNoCitizen","IAProNoUseOfForce"))
IAProSimple = data.frame()
IAProSimple = nrow("IAProNoAllegation","IAProNoPhone","IAProNoAddress","IAProNoOfficer","IAProNoCitizen","IAProNoUseOfForce")
IAProSimple = merge("IAProNoAllegation","IAProNoPhone","IAProNoAddress","IAProNoOfficer","IAProNoCitizen","IAProNoUseOfForce")
IAProSimple = merge("IAProNoAllegation$Var1","IAProNoPhone$Var1","IAProNoAddress$Var1","IAProNoOfficer$Var1","IAProNoCitizen$Var1","IAProNoUseOfForce$Var1")
IAProSimple = merge(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce,by.x="Var1", by.y="Freq")
IAProSimple = merge(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce,by.x="Var1")
IAProSimple = merge(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce,by.x="Var1", by.y="Freq")
IAProSimple = merge(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce,by.x="Var1", by=c("Var1","Freq"))
IAProSimple = rbind(IAProNoAllegation,IAProNoPhone,IAProNoAddress,IAProNoOfficer,IAProNoCitizen,IAProNoUseOfForce)
View(IAProSimple)
View(IAProNoAddress)
sum(IAProNoAddress$Freq)
sum(IAProNolAllegation$Freq)
sum(IAProNoAllegation$Freq)
sum(IAProNoCitizen)
sum(IAProNoCitizen$Freq)
sum(IAProNoOfficer$Freq)
sum(IAProNoPhone$Freq)
sum(IAProNoResolution$Freq)
sum(IAProNoUseOfForce$Freq)
View(IAProNoAddress)
View(IAProNoAddress)
View(IAProNoAllegation)
View(IAProNoAllegation)
View(IAProNoCitizen)
View(IAProNoOfficer)
View(IAProNoPhone)
View(IAProNoResolution)
View(IAProNoUseOfForce)
View(IAProReport)
View(IAProReportTally)
View(IAProSimple)
View(IAProSparse)
View(IAProSimple)
View(IAProNoAddress)
View(IAProNoAddress)
View(IAProNoAddress)
View(IAProNoAddress)
getwd()
rm(ls)
rm(list=ls, All=TRUE)
rm(list=ls)
rm(list=ls())
my_variable <- 10
my_variable
my_variable <- 10
my_variable
rm(list=ls())
my_variable <- 10
library(tidyverse)
library(tidyr)
ggpot(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
ggplot(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
library(ggplot2)
ggplot2(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
ggplot(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
load(mtcars)
read_table(mtcars)
library(dplyr)
read_table(mtcars)
library(datasets)
load(mtcars)
data(mtcars)
head(mtcars)
ggplot(dota=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
ggplot(data=mpg)+
geom_poin(mapping = aes(x = displ, y = hwy))
ggplot(data=mpg)+
geom_point(mapping = aes(x = displ, y = hwy))
filter(mpg, cyl = 8)
filter(mpg, cyl == 8)
filter(diamond, carat > 3)
library(help="datasets")
data(diamonds)
filter(diamond, carat > 3)
filter(diamonds, carat > 3)
rm(list=ls())
library(nycflights13)
library(tidyverse)
install.packages('tidyverse')
install.packages('nycflights13')
library(nycflights13)
library(tidyverse)
ndsuh <- load('~/Downloads/NSDUH-2015-DS0001-bndl-data-r/NSDUH-2015-DS0001-data/NSDUH-2015-DS0001-data-r.rda')
View(PUF2015_102016)
rm(list=ls())
library(nycflights13)
data(nycflights13)
data("flights")
View(flights)
flights %<% filter(dep_delay >= 2)
flights %.% filter(dep_delay >= 2)
flights %>% filter(dep_delay >= 2)
flights %>% filter(dest == 'IAH' | dest == 'HOU')
flights %>% filter(dest == 'DL' | carrier == 'UA')
library(dplyr)
flights %>% filter(between(air_time,0,260))
library(tidyverse)
library(readxl)
library(RSocrata)
library(data.table)
setwd('~/Documents/data_viz/health_insurance_marketplace/')
benifits <- read_csv('Benefits_Cost_Sharing_PUF.csv')
rates<- read_csv('Rate_PUF.csv')
service_area <- read_csv('Service_Area_PUF.csv')
plan_attributes <- read_csv('Plan_Attributes_PUF.CSV')
cross_walk <- read_csv('plan-id-crosswalk-puf.CSV')
network <- read_csv("Network_PUF.csv")
b_rules <- read_csv('Business_Rules_PUF_Reformat.csv')
aptc<- read_xlsx('County_Level_Demographics_2016.xlsx', sheet='APTC', skip = 2)
csr<- read_xlsx('County_Level_Demographics_2016.xlsx', sheet='CSR', skip = 2)
consumer_type <- read_xlsx('County_Level_Demographics_2016.xlsx', sheet='Consumer Type', skip = 2)
hh_income <- read_xlsx('County_Level_Demographics_2016.xlsx', sheet='Household Income', skip = 2)
race <- read_xlsx('County_Level_Demographics_2016.xlsx', sheet='Race', skip = 2)
age_group <- read_xlsx('County_Level_Demographics_2016.xlsx', sheet='Age Group', skip = 2)
dframeslist <- list(age_group, aptc, b_rules, benifits,
consumer_type,county_demos, cross_walk, csr, hh_income,
plan_attributes, race, rates, service_area)
ldframes <- lapply(dframeslist,function(d){
to_replace = colnames(d)
replace_with = gsub(" ","_",tolower(colnames(d)))
d <-setnames(d, c(to_replace), c(replace_with))
})
#^loop for other datasets?
dframeslist <- list(age_group, aptc, b_rules, benifits,
consumer_type,county_demos, cross_walk, csr, hh_income,
plan_attributes, race, rates, service_area)
#^loop for other datasets?
dframeslist <- list(age_group, aptc, b_rules, benifits,
consumer_type, cross_walk, csr, hh_income,
plan_attributes, race, rates, service_area)
ldframes <- lapply(dframeslist,function(d){
to_replace = colnames(d)
replace_with = gsub(" ","_",tolower(colnames(d)))
d <-setnames(d, c(to_replace), c(replace_with))
})
service_area <- read_csv('Service_Area_PUF.csv')
service_area <- read_csv('ServiceArea_PUF.csv')
ldframes <- lapply(dframeslist,function(d){
to_replace = colnames(d)
replace_with = gsub(" ","_",tolower(colnames(d)))
d <-setnames(d, c(to_replace), c(replace_with))
})
#^loop for other datasets?
dframeslist <- list(age_group, aptc, b_rules, benifits,
consumer_type, cross_walk, csr, hh_income,
plan_attributes, race, rates, service_area)
ldframes <- lapply(dframeslist,function(d){
to_replace = colnames(d)
replace_with = gsub(" ","_",tolower(colnames(d)))
d <-setnames(d, c(to_replace), c(replace_with))
})
hh_income <- hh_income %>% filter(state_name %in% c('MI','WI','IL','IN'))
race <- race %>% filter(state_name %in% c('MI','WI','IL','IN'))
consumer_type <- consumer_type %>% filter(state_name %in% c('MI','WI','IL','IN'))
csr <- csr %>% filter(state_name %in% c('MI','WI','IL','IN'))
aptc <- aptc %>% filter(statecode %in% c('MI','WI','IL','IN'))
b_rules <- b_rules %>% filter(statecode %in% c('MI','WI','IL','IN'))
network <- network %>% filter(statecode %in% c('MI','WI','IL','IN'))
cross_walk <- cross_walk %>% filter(statecode %in% c('MI','WI','IL','IN'))
rates <- rates %>% filter(statecode %in% c('MI','WI','IL','IN'))
plan_attributes <- plan_attributes %>% filter(statecode %in% c('MI','WI','IL','IN'))
service_area <- service_area %>% filter(statecode %in% c('MI','WI','IL','IN'))
benifits <- benifits %>% filter(statecode %in% c('MI','WI','IL','IN'))
View(cross_walk)
View(network)
#^loop for other datasets?
dframeslist <- list(age_group, aptc, b_rules, benifits,
consumer_type, cross_walk, csr, hh_income,
plan_attributes, network, race, rates, service_area)
ldframes <- lapply(dframeslist,function(d){
to_replace = colnames(d)
replace_with = gsub(" ","_",tolower(colnames(d)))
d <-setnames(d, c(to_replace), c(replace_with))
})
hh_income <- hh_income %>% filter(state_name %in% c('MI','WI','IL','IN'))
race <- race %>% filter(state_name %in% c('MI','WI','IL','IN'))
consumer_type <- consumer_type %>% filter(state_name %in% c('MI','WI','IL','IN'))
csr <- csr %>% filter(state_name %in% c('MI','WI','IL','IN'))
aptc <- aptc %>% filter(state_name %in% c('MI','WI','IL','IN'))
b_rules <- b_rules %>% filter(statecode %in% c('MI','WI','IL','IN'))
network <- network %>% filter(statecode %in% c('MI','WI','IL','IN'))
cross_walk <- cross_walk %>% filter(state %in% c('MI','WI','IL','IN'))
rates <- rates %>% filter(statecode %in% c('MI','WI','IL','IN'))
plan_attributes <- plan_attributes %>% filter(statecode %in% c('MI','WI','IL','IN'))
service_area <- service_area %>% filter(statecode %in% c('MI','WI','IL','IN'))
benifits <- benifits %>% filter(statecode %in% c('MI','WI','IL','IN'))
race %>%
ggplot(aes(x=state_name ,y =asian ))+
geom_bar(stat='identity')+
facet_geo(~state_name)
library(ggplot2)
race %>%
ggplot(aes(x=state_name ,y =asian ))+
geom_bar(stat='identity')+
facet_geo(~state_name)
install.packages('tidyverse')
install.packages('tidyverse')
install.packages('tidyverse')
library(ggplot2)
race %>%
ggplot(aes(x=state_name ,y =asian ))+
geom_bar(stat='identity')+
facet_geo(~state_name)
library(tidyverse)
race %>%
ggplot(aes(x=state_name ,y =asian ))+
geom_bar(stat='identity')+
facet_geo(~state_name)
#facet_geo
race %>%
ggplot(aes(x=state_name ,y =asian ))+
geom_bar(stat='identity')+
facet_geo(~state_name)
install.packages('ggplot2')
install.packages('ggplot2')
install.packages('ggplot2')
install.packages('ggplot2')
install.packages('ggplot2')
install.packages('ggplot2')
install.packages('ggplot2')
install.packages('ggplot2')
install.packages('ggplot2')
install.packages("mgcv")
library(ggplot2)
#facet_geo
race %>%
ggplot(aes(x=state_name ,y =asian ))+
geom_bar(stat='identity')+
facet_geo(~state_name)
library(tidyverse)
library(ggplot2)
#facet_geo
race %>%
ggplot(aes(x=state_name ,y =asian ))+
geom_bar(stat='identity')+
facet_geo(~state_name)
#facet_geo
race %>%
ggplot(aes(x=state_name ,y =asian ))+
geom_bar(stat='identity')+
facet_grid(~state_name)
View(race)
#facet_geo
race %>%
ggplot(aes(x=county_name ,y = asian ))+
geom_bar(stat='identity')+
facet_grid(~state_name)
#facet_geo
race %>%
ggplot(aes(x=county_name ,y = asian ))+
geom_histogram(stat='identity')+
facet_grid(~state_name)
#facet_geo
race %>%
ggplot(aes(x=county_name ,y = asian ))+
geom_histogram(stat='identity')+
facet_wrap(~state_name)
#facet_geo
race %>%
ggplot(aes(x=county_name ,y = asian ))+
geom_histogram(stat='identity')+
facet_geo(~state_name)
View(age_group)
age_group <- age_group %>% filter(state_name %in% c('MI','WI','IL','IN'))
View(age_group)
View(benifits)
unique(benefits$benefitname)
unique(benifits$benefitname)
benifits %>% filter(benifitname %in% [list()])
unique(benifits$benefitname)[185]
unique(benifits$benefitname)[c(185,186)]
c(unique(benifits$benefitname)[c(185,186)])
list(unique(benifits$benefitname)[c(185,186)])
benifits %>% filter(grep("Mental|Substance", benefitname))
benefits[grep("Mental|Substance", benfits$benefitname),]
benifits[grep("Mental|Substance", benfits$benefitname),]
benefits[grep("Mental|Substance", benefits$benefitname),]
benifits[grep("Mental|Substance", benifits$benefitname),]
unique(benifits[grep("Mental|Substance", benifits$benefitname),]$benefitnames)
unique(benifits[grep("Mental|Substance", benifits$benefitname),]$benefitname)
#exploration of health plans in the 4 states with mental health and substance use benifits
mh_benifit_names = c(unique(benifits[grep("Mental|Substance", benifits$benefitname),]$benefitname))
mh_benifit_pids = c(unique(benifits[grep("Mental|Substance", benifits$benefitname),]$benefitname))
mh_benifit_pids
mh_benifit_pids = c(unique(benifits[grep("Mental|Substance", benifits$benefitname),]$planid))
mh_benifit_pids
unique(benifits$planid)==mh_benifit_pids
length(benifits$planid)
length(mh_benifit_pids)
mh_benifit_states = c(unique(benifits[grep("Mental|Substance", benifits$benefitname),]$statecode))
benifits %>%
filter(benifits[grep("Mental|Substance", benifits$benefitname),])
ggplot(data = )
benifits %>%
filter(benifits %>% in mh_benifit_names)
benifits %>%
filter(benifits %in% mh_benifit_names)
quit()
